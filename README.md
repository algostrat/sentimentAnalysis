# sentimentAnalysis
For this project, we gathered social media posts data from platforms such as Twitter, and determined which posts are trending, abusive, and their overall sentiment. After a post had been retrieved and analyzed by our backend components (or systems), we showed the post (and metadata about it, such as when it was posted, by whom, etc) and our analysis of it on our front-end web-based platform. To develop this application, we used several different technologies. To ensure that our application could be easily scalable, we placed an emphasis on modular design and developed multiple components (or modules) to perform various tasks. For example, we have developed a social media crawling component that is responsible for gathering the latest social media post data, a sentiment analysis component, an abusive language analysis component, a trending analysis component, and front-end component(s). These components interact with each other to transform, massage, and ultimately, present data in a simple, interactive, and informative manner. The solution we are developing will be beneficial to users of all fields. The data we present contains information that could aid those in law enforcement, marketing, news organizations, and more.

This proposal responds to an RFP from rewardStyle Social Media / Blog – Sentiment Analysis. RewardStyle seeks a solution to the problem of analyzing and predicting sentiment on social media posts. The company rewardStyle requests a web application dashboard that displays sentiment analysis, trend discovery, and abuse flagging data.

Sentiment Analysis can help rewardStyle better understand public reaction to a specific product. Having the ability to observe sentiment, discover trends and see abusive posts can significantly improve rewardStyles future decision making. The flagging of abusive posts is also an important feature that allows for a safer internet experience. In general, sentiment analysis can be used by rewardStyle and many other companies to gain insight on social media posts. 

The goal for this project is to acquire specific data from Twitter and research the feasibility for scraping Twitter data. The specific data will be in accordance with what Kurt Radwanski (rewardStyle engineer) suggested, which is posts involving holiday themed hashtags. The data will be used to analyze posts for sentiment scores that will then be plotted. As of this proposal, a lite version of a crawler for downloading twitter data has been established but a plan to automate this server to download data on a timely basis will be completed. We will demonstrate the front-end application and preliminary discoveries and possible algorithms as to how to analyze trends and further classify social media blog posts to an end user.

# Overall System Design with Block Diagrams
Below is a visual representation of the system in the form of a block diagram. It is important to note how each component is interacting with each other. (See 2.4 for high level explanation and section 3 for implementation)

# Sub-System Design and High-Level Implementation:
Crawler This subsystem will retrieve Instagram post metadata (such as the caption and hashtags) and store it in our centralized storage server. The information stored will provide the sentiment analysis subsystem with data to analyze, and the frontend web dashboard with post data to show.
The components for this subsystem are written in the PHP programming language and a specific API(Twitter). These two components are responsible for retrieving the necessary data for sentiment analysis. 
The crawler will collect twitter data and store it in a SQL server that format that will be necessary for sentiment analysis. It will also interact with the storage subsystem since it will be sending all the data acquired from the twitter API. 
Some challenges that can occur implementing a crawler are programming bugs that would require debugging, not using the Twitter API correctly to retrieve the necessary tweets(data), potential restriction of data, etc.   
Analyzing Sentiment This subsystem will use the data from the storage to perform sentiment analysis taking the data as input and provide classification to each instance in the database. Each updated instance will be searched for instances of abuse by a metric score and presented to the user in the web application component. Trends will be bulk analyzed for top scoring word counts over recent time in order to discover trends. 
The components for this subsystem will be using mainly Python as the programming language and Python’s TextBlob library for sentiment analysis and Python’s Plotly wrapper library for generating a web page dashboard.  
Advantage of using Python’s Plotly wrapper library is that it generates pages that are native to both mobile, tablet, and PCs so cross platform ability is achieved easily. Whereas the Python’s TextBlob library provides a simple API useful for common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, and translation.
The sentiment engine is part of the back end and is meant to find sentiment, trends, abusive posts and pipeline these findings to a front-end web page generating library. The sentiment analysis attained at this implementation will incorporate sentiment scores/metrics that can be graphically displayed on the front-end application. The sentiment will be generated on all the text for each instance in the database. A score will be received which we will plot on a graph that will then be served to the front-end web page. Lastly, a lite version of a trend discovering algorithm will be implemented that will also be pipelined to its own respective graph on the web page. 
The challenges associated with this sub-system implementation would be to ensure the unknown accuracy of the model like does the model produce sentiment analysis which is giving accurate scores/metrics compared to other pretrained models to ensure its reliability. Another is ensuring that libraries that are being used to pre-process the text and perform sentiment analysis function well together as intended. Lastly, the challenge of considering the possibility and volume of false positives or false negatives in a reasonably adjustable fashion.
Discovering Trends This subsystem will use the data from the storage to perform trend analysis on the data taken as input and provide a bag-of-words for each instance in the database. Each updated instance will go through association rules for instances of trends to be accumulated and presented to the user in the web application component. Trends will be bulk analyzed for top scoring trend counts over recent time in order to discover trends. 
The components for this subsystem will be using mainly Python as the programming language and Python’s NLTK library for the six processes to convert the input from data to make it into bag-of-words then using Python’s Apriori Library to perform Association Rule Mining to accumulate the trends. Lastly, Python’s Plotly wrapper library for generating a web page dashboard and Python’s wordcloud library will be used to produce the final product presented through the front-end web page generating library. 
Advantage of using Python’s Plotly wrapper library is that it generates pages that are native to both mobile, tablet, and PCs so cross platform ability is achieved easily. Whereas the Python’s NLTK library provides a simple API useful for common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, lemmatizing, parsing, and tokenization. Lastly, Python’s wordcloud library provides a variety of ways to produce word clouds hence is useful for the final product being presented.  
The trend discovery is part of the back end and is meant to find trends and pipeline these findings to a front-end web page generating library. The trend analysis attained at this implementation will incorporate six processes that can be used to get bag-of-words from our input from the storage and through using association rules on the bag-of-word we attain the trends which will be graphically displayed on the front-end application. The trends will be generated on bag-of-words for each instance in the database. A frequency will be received for each trend and will be used to produce the word cloud and that will then be served to the front-end web page. For now, a lite version of a trend discovering algorithm will be implemented that will also be pipelined to its own respective graph on the web page.  
The challenges associated with this sub-system implementation would be to ensure the unknown accuracy of the model like does the model produce trend analysis which is giving accurate frequencies compared to other pretrained models to ensure its reliability. Another is ensuring that libraries that are being used to pre-process the text and perform sentiment analysis function well together as intended. Lastly, the challenge of taking in the account of the possibility and volume of false positives or false negatives in a reasonably adjustable fashion.
Classifying abusive instances This subsystem component is a trained classification model that detects if any instance in the preprocessed data frame contains a flagged abusive post. A classifier will be trained using publicly available labeled datasets, but a choice of a machine learning method will have to be chosen in the implementation and testing phase. Once an optimal classifier is chosen, it will be used to curate a list of all possible abusive posts that is pipelined to a front-end component where the user can view these instances and review them. 
Storage This subsystem will be the main database for this project. It will communicate data with the crawler, analyzing sentiment, and web application subsystems. 
One component used in this subsystem is a SQL database. The database will be used to organize the data acquired by the crawler subsystem. The data will be used by the web application to display our results. 
This storage subsystem will interact with the crawler, web application and the analyzing sentiment subsystems. The crawler subsystem will be sending data from twitter to the storage. That data will then interact with the python code created in the analyzing sentiment subsystem. Lastly, the storage will send information to the web application that will then be used to display the data on the web application.
Some problems that may occur when implementing this subsystem includes organizing the information received. This is because the crawler algorithm will be sending large batches of information to the database. The database then needs to organize this information properly for it to be used for sentiment analysis.
Web Application This subsystem will acquire data curated by the sentiment analysis component from storage and then display the results to the user. The web application will also update storage to incur posts flagged abusive by the user. The web application will also present trends curated by the sentiment analysis component though charts and diagrams to the user.
The components for this subsystem include using programming languages like Python and HTML, CSS, and JavaScript. We will also be using other components like Plotly to present our data. Plotly will use Flask, which is a micro web framework that will serve data to each front-end component. Plotly will organize our website and be able to display a dashboard structure. Both HTML and CSS will be used to create and organize the website to view our data. 
The web application will collect all instances from the database and display results in a user-friendly format. This will be done by the Python programming language.  
Some challenges we might face include being able to acquire and display the proper data from the database, avoiding program crashing bugs that would require debugging, the final application not being user friendly and confusing to potentially navigate, etc.

