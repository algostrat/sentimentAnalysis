{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I have removed all greek characters, @,numbers.\n",
    "#Also I have removed 'hmm' word and it's variants\n",
    "#Creating a dictionary to map words such as luv to love, wud to would.Need more suggestions on this.nyc:nice\n",
    "#Removed stop words\n",
    "#Performed lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sb\n",
    "from nltk.corpus import stopwords\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import unidecode\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize \n",
    "import matplotlib.animation as animation\n",
    "import operator\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Hash words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>#run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause they...</td>\n",
       "      <td>#lyft #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now #motivation</td>\n",
       "      <td>#motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when a father is dysfunctional and is so selfi...   \n",
       "1  thanks for #lyft credit i can't use cause they...   \n",
       "2                                bihday your majesty   \n",
       "3  #model i love you take with you all the time i...   \n",
       "4                factsguide: society now #motivation   \n",
       "\n",
       "                       Hash words  \n",
       "0                            #run  \n",
       "1  #lyft #disapointed #getthanked  \n",
       "2                     No hashtags  \n",
       "3                          #model  \n",
       "4                     #motivation  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_E6oV3lV.csv')\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "#Code to remove @\n",
    "df['clean_tweet'] = df['tweet'].apply(lambda x : ' '.join([tweet for tweet in x.split()if not tweet.startswith(\"@\")]))\n",
    "\n",
    "#Removing numbers\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x : ' '.join([tweet for tweet in x.split() if not tweet == '\\d*']))\n",
    "\n",
    "#Removing all the greek characters using unidecode library\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x : ' '.join([unidecode.unidecode(word) for word in x.split()])) \n",
    "\n",
    "#Removing the word 'hmm' and it's variants\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x : ' '.join([word for word in x.split() if not word == 'h(m)+' ]))\n",
    "\n",
    "#Code for removing slang words\n",
    "d = {'luv':'love','wud':'would','lyk':'like','wateva':'whatever','ttyl':'talk to you later',\n",
    "               'kul':'cool','fyn':'fine','omg':'oh my god!','fam':'family','bruh':'brother',\n",
    "               'cud':'could','fud':'food','lol':'laugh out loud', 'wtf':'what the fuck','wyd':'what are you doing',\n",
    "                'wdym':'what do you mean','lmao':'laugh my ass off','fml':'fuck my life','np':'no problem',\n",
    "                'ffs':'for fucks sake','nvm':'nevermind','bro':'brother','bra':'brother','tldr':'too long, didn\\'t read',\n",
    "                'stfu':'shut the fuck up', 'tbh':'to be honest','idek':'i don\\'t even know',\n",
    "                'diy': 'Do it yourself','rn': 'right now', 'btw':'by the way','u':'you' ,'imo': 'in my opinion', 'ily':'i love you',\n",
    "    'bf':'boyfriend','gf':'girlfriend','5g':'5th generation','tldr':'too long didn\\'t read', 'rofl':'rolling on the floor laughing',\n",
    "    'lmk':'let me know', 'hmu':'hit me up','tba':'to be announced','asap':'as soon as possible','roi':'return on investment','tgif':'thank goodness it\\'s friday'} ## Need a huge dictionary\n",
    "words = \"I luv myself\"\n",
    "words = words.split()\n",
    "reformed = [d[word] if word in d else word for word in words]\n",
    "reformed = \" \".join(reformed)\n",
    "\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x : ' '.join(d[word] if word in d else word for word in x.split()))\n",
    "\n",
    "#Finding words with # attached to it\n",
    "df['#'] = df['clean_tweet'].apply(lambda x : ' '.join([word for word in x.split() if word.startswith('#')]))\n",
    "\n",
    "frame = df['#']\n",
    "\n",
    "frame = pd.DataFrame(frame)\n",
    "\n",
    "frame = frame.rename({'#':'Count(#)'},axis = 'columns')\n",
    "\n",
    "frame[frame['Count(#)'] == ''] = 'No hashtags'\n",
    "\n",
    "data_frame = pd.concat([df,frame],axis = 1)\n",
    "\n",
    "data_frame.drop('#',axis = 1,inplace = True)\n",
    "\n",
    "#Column showing whether the corresponding tweet has a hash tagged word or not\n",
    "data_frame = data_frame.rename({'Count(#)':'Hash words'},axis = 'columns')\n",
    "\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONT RUN - TOO SLOW!!! -- autocorrect -- TEST THE ACCURACY OF THIS\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "word = \"plumming\"\n",
    "print(spell.correction(word))\n",
    "print(spell.word_probability(word))\n",
    "data_frame['clean_tweet'] = data_frame['clean_tweet'].progress_apply(lambda x : ' '.join([spell.correction(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (don't do this... yet... keeping this here for later use in project)\n",
    "#removing anything that's not an englsih word while ignoring digits \n",
    "# imay not incorporate this further dependent on whether it performs well or not\n",
    "# check for cursewords\n",
    "import nltk \n",
    "from better_profanity import profanity #\n",
    "#nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run this either, this removes words if not in english dictionary\n",
    "\n",
    "#\" \".join(w for w in nltk.wordpunct_tokenize(sent) if w.lower() in words or not w.isalpha())\n",
    "data_frame['clean_tweet'][0] = \"man fuck you sdf sdg  you racist peice of shit i hope you die of aids you fucker\"\n",
    "data_frame['clean_tweet'] = data_frame['clean_tweet'].apply(lambda x : ' '.join(w for w in nltk.wordpunct_tokenize(x) if w.lower() in words or not w.isalpha() or profanity.contains_profanity(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START of native stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump', 'politics', 'allahsoil', 'libtard']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Collecting positive hashtags\n",
    "\n",
    "hash_positive = []\n",
    "hash_negative = []\n",
    "\n",
    "def hashtag_extract(x):\n",
    "    hashtags = []\n",
    "    # Loop over the words in the tweet\n",
    "    for i in x:\n",
    "        ht = re.findall(r\"#(\\w+)\", i)\n",
    "        hashtags.append(ht)\n",
    "\n",
    "    return hashtags\n",
    "\n",
    "hash_positive = hashtag_extract(data_frame['clean_tweet'][data_frame['label'] == 0])\n",
    "\n",
    "# extracting hashtags from racist/sexist tweets\n",
    "hash_negative = hashtag_extract(data_frame['clean_tweet'][data_frame['label'] == 1])\n",
    "\n",
    "# Converting a multidimensional list to a 1-D list\n",
    "hash_positive = sum(hash_positive,[])\n",
    "hash_negative = sum(hash_negative,[])\n",
    "\n",
    "q = Counter(hash_positive)\n",
    "q = dict(q.most_common())\n",
    "\n",
    "l_positive_count = list(q.values())\n",
    "\n",
    "l_positive_count[0:4]\n",
    "\n",
    "r = Counter(hash_negative)\n",
    "r = dict(r.most_common())\n",
    "\n",
    "l_negative_count = list(r.values())\n",
    "\n",
    "l_negative_count[0:4]\n",
    "\n",
    "l_positive_values = list(q.keys())\n",
    "\n",
    "l_positive_values[0:4]\n",
    "\n",
    "l_negative_values = list(r.keys())\n",
    "\n",
    "l_negative_values[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive_Words</th>\n",
       "      <th>Positive_Count</th>\n",
       "      <th>Negative_Words</th>\n",
       "      <th>Negative_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>1531</td>\n",
       "      <td>trump</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>874</td>\n",
       "      <td>politics</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>healthy</td>\n",
       "      <td>570</td>\n",
       "      <td>allahsoil</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smile</td>\n",
       "      <td>548</td>\n",
       "      <td>libtard</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thankful</td>\n",
       "      <td>491</td>\n",
       "      <td>liberal</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fun</td>\n",
       "      <td>434</td>\n",
       "      <td>sjw</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>life</td>\n",
       "      <td>405</td>\n",
       "      <td>retweet</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>summer</td>\n",
       "      <td>367</td>\n",
       "      <td>black</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model</td>\n",
       "      <td>364</td>\n",
       "      <td>miamia</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>affirmation</td>\n",
       "      <td>363</td>\n",
       "      <td>hate</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cute</td>\n",
       "      <td>354</td>\n",
       "      <td>tampa</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i_am</td>\n",
       "      <td>352</td>\n",
       "      <td>blm</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>blog</td>\n",
       "      <td>345</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>me</td>\n",
       "      <td>333</td>\n",
       "      <td>brexit</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fathersday</td>\n",
       "      <td>332</td>\n",
       "      <td>bigot</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>silver</td>\n",
       "      <td>299</td>\n",
       "      <td>sikh</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gold</td>\n",
       "      <td>298</td>\n",
       "      <td>calgary</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>altwaystoheal</td>\n",
       "      <td>295</td>\n",
       "      <td>temple</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>283</td>\n",
       "      <td>wso</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bihday</td>\n",
       "      <td>278</td>\n",
       "      <td>obama</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Positive_Words  Positive_Count Negative_Words  Negative_Count\n",
       "0            love            1531          trump             133\n",
       "1        positive             874       politics              94\n",
       "2         healthy             570      allahsoil              92\n",
       "3           smile             548        libtard              76\n",
       "4        thankful             491        liberal              75\n",
       "5             fun             434            sjw              74\n",
       "6            life             405        retweet              57\n",
       "7          summer             367          black              44\n",
       "8           model             364         miamia              38\n",
       "9     affirmation             363           hate              32\n",
       "10           cute             354          tampa              32\n",
       "11           i_am             352            blm              28\n",
       "12           blog             345       hispanic              28\n",
       "13             me             333         brexit              27\n",
       "14     fathersday             332          bigot              27\n",
       "15         silver             299           sikh              27\n",
       "16           gold             298        calgary              27\n",
       "17  altwaystoheal             295         temple              26\n",
       "18      beautiful             283            wso              26\n",
       "19         bihday             278          obama              26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe to represent top 20 positive and negative hashtag words\n",
    "l1 = pd.DataFrame(l_positive_values[0:20],columns = ['Positive_Words'])\n",
    "l2 = pd.DataFrame(l_positive_count[0:20],columns = ['Positive_Count'])\n",
    "l3 = pd.DataFrame(l_negative_values[0:20],columns = ['Negative_Words'])\n",
    "l4 = pd.DataFrame(l_negative_count[0:20],columns = ['Negative_Count'])\n",
    "z = pd.concat([l1,l2,l3,l4],axis = 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Animated plot for positive words with their frequency\n",
    "fig = px.bar(z, x=\"Positive_Words\", y=\"Positive_Count\",animation_frame=\"Positive_Count\",\n",
    "            hover_name=\"Positive_Words\")\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1200\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animated plot for negative words with their frequency\n",
    "fig = px.bar(z, x=\"Negative_Words\", y=\"Negative_Count\",animation_frame=\"Negative_Count\",\n",
    "            hover_name=\"Negative_Words\")\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1200\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal histogram of positive words\n",
    "fig = px.bar(z, x=\"Positive_Words\", y=\"Positive_Count\",\n",
    "            hover_name=\"Positive_Words\",color = 'Positive_Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal histogram of negative words\n",
    "fig = px.bar(z, x=\"Negative_Words\", y=\"Negative_Count\",\n",
    "            hover_name=\"Negative_Words\",color= 'Negative_Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my text preprocessing\n",
    "\n",
    "#remove hashtags, don't do this yet until you run hastag analyzer above\n",
    " # remove hashtags only\n",
    "data_frame['clean_tweet2'] = data_frame['clean_tweet'].apply(lambda x : ' '.join([word.replace('#', '') for word in x.split()]))\n",
    "\n",
    "#removing links this removes everythin !!!\n",
    "#re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text)\n",
    "#test = data_frame[0:7]\n",
    "#test[\"clean_tweet\"][0] = \"New 12\\\" https://t.co/Xj1e5qHVxP\"\n",
    "#test\n",
    "#test['clean_tweet'] = test['clean_tweet'].apply(lambda x : ' '.join([re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",word) for word in x.split()]))\n",
    "#test\n",
    "data_frame['clean_tweet2'] = data_frame['clean_tweet2'].apply(lambda x : ' '.join([re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",word) for word in x.split()]))\n",
    "\n",
    "#reduce excess letters\n",
    "def reduce_lengthening(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "#print reduce_lengthening( \"finallllllly\" )\n",
    "data_frame['clean_tweet2'] = data_frame['clean_tweet2'].apply(lambda x : ' '.join([reduce_lengthening(word) for word in x.split()]))\n",
    "\n",
    "#removing single letters except single digits or i or a \n",
    "#re.sub(r'(?:^| )\\w(?:$| )', ' ', text).strip() #removes digits too\n",
    "data_frame['clean_tweet'] = data_frame['clean_tweet'].apply(lambda x : ' '.join( [w for w in x.split() if (len(w)>1 or w.isdigit() or w.lower()=='a' or w.lower() =='i')] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Hash words</th>\n",
       "      <th>clean_tweet2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>#run</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause they...</td>\n",
       "      <td>#lyft #disapointed #getthanked</td>\n",
       "      <td>thanks for lyft credit i can t use cause they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>No hashtags</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now #motivation</td>\n",
       "      <td>#motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when a father is dysfunctional and is so selfi...   \n",
       "1  thanks for #lyft credit i can't use cause they...   \n",
       "2                                bihday your majesty   \n",
       "3  #model i love you take with you all the time i...   \n",
       "4                factsguide: society now #motivation   \n",
       "\n",
       "                       Hash words  \\\n",
       "0                            #run   \n",
       "1  #lyft #disapointed #getthanked   \n",
       "2                     No hashtags   \n",
       "3                          #model   \n",
       "4                     #motivation   \n",
       "\n",
       "                                        clean_tweet2  \n",
       "0  when a father is dysfunctional and is so selfi...  \n",
       "1  thanks for lyft credit i can t use cause they ...  \n",
       "2                                bihday your majesty  \n",
       "3  model i love you take with you all the time in...  \n",
       "4                  factsguide society now motivation  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38424c78314b4793b39e066b31eae8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff6b6aa1a0c49e2955f2eb8d4019a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=31962.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#text word correcting\n",
    "\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "\n",
    "# error\n",
    "#dictionary_path = pkg_resources.resource_filename(\n",
    "#    \"symspellpy\", \"frequency_dictionary_en_500_000.txt\")\n",
    "\n",
    "#default smaller dictionary\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "\n",
    "bigram_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
    "# term_index is the column of the term and count_index is the\n",
    "# column of the term frequency\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "\n",
    "# lookup suggestions for multi-word input strings (supports compound\n",
    "# splitting & merging)\n",
    "input_term = (\"whereis th fuckiing cunt shit elove hehad dated forImuch of thepast who \"\n",
    "              \"couldnt read in sixtgrade and ins pired him\")\n",
    "# max edit distance per lookup (per single word, not per whole input string)\n",
    "suggestions = sym_spell.lookup_compound(input_term, max_edit_distance=2)\n",
    "# display suggestion term, edit distance, and term frequency\n",
    "\n",
    "#for suggestion in suggestions:\n",
    "#    print(suggestion.term)\n",
    "\n",
    "#print(suggestions[0].term)\n",
    "    \n",
    "#test = data_frame[0:7]\n",
    "#test[\"clean_tweet\"][0] = input_term\n",
    "#test['corrected_tweet'] = test['clean_tweet'].progress_apply(lambda x : ''.join([word.term for word in sym_spell.lookup_compound(x, max_edit_distance=2)]))\n",
    "#test\n",
    "\n",
    "data_frame['corrected_tweet'] = data_frame['clean_tweet2'].progress_apply(lambda x : ''.join([word.term for word in sym_spell.lookup_compound(x, max_edit_distance=2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Hash words</th>\n",
       "      <th>clean_tweet2</th>\n",
       "      <th>corrected_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>#run</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause they...</td>\n",
       "      <td>#lyft #disapointed #getthanked</td>\n",
       "      <td>thanks for lyft credit i can t use cause they ...</td>\n",
       "      <td>thanks for left credit i can to use cause they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>No hashtags</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>by day your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now #motivation</td>\n",
       "      <td>#motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>fact guide society now motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when a father is dysfunctional and is so selfi...   \n",
       "1  thanks for #lyft credit i can't use cause they...   \n",
       "2                                bihday your majesty   \n",
       "3  #model i love you take with you all the time i...   \n",
       "4                factsguide: society now #motivation   \n",
       "\n",
       "                       Hash words  \\\n",
       "0                            #run   \n",
       "1  #lyft #disapointed #getthanked   \n",
       "2                     No hashtags   \n",
       "3                          #model   \n",
       "4                     #motivation   \n",
       "\n",
       "                                        clean_tweet2  \\\n",
       "0  when a father is dysfunctional and is so selfi...   \n",
       "1  thanks for lyft credit i can t use cause they ...   \n",
       "2                                bihday your majesty   \n",
       "3  model i love you take with you all the time in...   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                     corrected_tweet  \n",
       "0  when a father is dysfunctional and is so selfi...  \n",
       "1  thanks for left credit i can to use cause they...  \n",
       "2                                by day your majesty  \n",
       "3  model i love you take with you all the time in...  \n",
       "4                  fact guide society now motivation  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wordcloud\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_words = ' '.join([word for word in data_frame['corrected_tweet'][data_frame['label'] == 0]])\n",
    "wordcloud = WordCloud(width = 800, height = 500, max_font_size = 110,max_words = 100).generate(normal_words)\n",
    "print('Normal words')\n",
    "plt.figure(figsize= (12,8))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear',cmap='viridis')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_words = ' '.join([word for word in data_frame['corrected_tweet'][data_frame['label'] == 1]])\n",
    "wordcloud = WordCloud(width = 800, height = 500, max_font_size = 110,max_words = 100).generate(normal_words)\n",
    "print('Normal words')\n",
    "plt.figure(figsize= (12,8))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords\n",
    "data_frame['clean_tweet'] = data_frame['clean_tweet'].apply(lambda x : ' '.join([word for word in x.split() if not word in set(stopwords.words('english'))]))\n",
    "data_frame['corrected_tweet'] = data_frame['corrected_tweet'].apply(lambda x : ' '.join([word for word in x.split() if not word in set(stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmitization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data_frame['clean_tweet'] = data_frame['clean_tweet'].apply(lambda x : ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "data_frame['corrected_tweet'] = data_frame['corrected_tweet'].apply(lambda x : ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "adwait = data_frame\n",
    "#adwait.head()\n",
    "data_frame['clean_tweet'] = data_frame['clean_tweet'].apply(lambda x : ' '.join([ps.stem(word) for word in x.split()]))\n",
    "data_frame['corrected_tweet'] = data_frame['corrected_tweet'].apply(lambda x : ' '.join([ps.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Hash words</th>\n",
       "      <th>clean_tweet2</th>\n",
       "      <th>corrected_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunction. ...</td>\n",
       "      <td>#run</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunct run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank #lyft credit can't use caus offer wheelc...</td>\n",
       "      <td>#lyft #disapointed #getthanked</td>\n",
       "      <td>thanks for lyft credit i can t use cause they ...</td>\n",
       "      <td>thank left credit use caus offer wheelchair va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesti</td>\n",
       "      <td>No hashtags</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>day majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model love take time urd+-!!! dddd d|d|d|</td>\n",
       "      <td>#model</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "      <td>model love take time ord add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: societi #motiv</td>\n",
       "      <td>#motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>fact guid societi motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  father dysfunct selfish drag kid dysfunction. ...   \n",
       "1  thank #lyft credit can't use caus offer wheelc...   \n",
       "2                                     bihday majesti   \n",
       "3         #model love take time urd+-!!! dddd d|d|d|   \n",
       "4                         factsguide: societi #motiv   \n",
       "\n",
       "                       Hash words  \\\n",
       "0                            #run   \n",
       "1  #lyft #disapointed #getthanked   \n",
       "2                     No hashtags   \n",
       "3                          #model   \n",
       "4                     #motivation   \n",
       "\n",
       "                                        clean_tweet2  \\\n",
       "0  when a father is dysfunctional and is so selfi...   \n",
       "1  thanks for lyft credit i can t use cause they ...   \n",
       "2                                bihday your majesty   \n",
       "3  model i love you take with you all the time in...   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                     corrected_tweet  \n",
       "0      father dysfunct selfish drag kid dysfunct run  \n",
       "1  thank left credit use caus offer wheelchair va...  \n",
       "2                                        day majesti  \n",
       "3                       model love take time ord add  \n",
       "4                            fact guid societi motiv  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "corpus = []\n",
    "for i in range(0,31962):\n",
    "    tweet = data_frame['clean_tweet'][i]\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    tweet = [ps.stem(word) for word in tweet if not word in set(stopwords.words('english'))]\n",
    "    tweet = ' '.join(tweet)\n",
    "    corpus.append(tweet)\n",
    "\n",
    "corpus_corrected = []\n",
    "for i in range(0,31962):\n",
    "    tweet = data_frame['corrected_tweet'][i]\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    tweet = [ps.stem(word) for word in tweet if not word in set(stopwords.words('english'))]\n",
    "    tweet = ' '.join(tweet)\n",
    "    corpus_corrected.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring all the tweets are tokenized into individual words\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Techniques to convert the tweets into Bag-of-Words, TF-IDF, and Word Embeddings\n",
    "#Building various classifiers: -\n",
    "#TF-IDF approach\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2,stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "X1 = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
    "Y1 = df.loc[:,'label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(data_frame['clean_tweet'], data_frame['label'], test_size = 0.3, random_state=0, shuffle = True, stratify=data_frame['label'])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X1_train_vect = vectorizer.fit_transform(X1_train)\n",
    "Y1 = df.loc[:,'label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest using pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = Pipeline([('tfidf', TfidfVectorizer()), ('rf', RandomForestClassifier())])\n",
    "rf.fit(X1_train, Y1_train)\n",
    "y_pred = rf.predict(X1_test)\n",
    "print(pd.crosstab(Y1_test,y_pred,rownames=['Actual'],colnames=['Predicted']))\n",
    "print(classification_report(Y1_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(rf.predict([\"i swaer to trump\"]))\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all my test processing goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Hash words</th>\n",
       "      <th>clean_tweet2</th>\n",
       "      <th>corrected_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunction. ...</td>\n",
       "      <td>#run</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunct run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank #lyft credit can't use caus offer wheelc...</td>\n",
       "      <td>#lyft #disapointed #getthanked</td>\n",
       "      <td>thanks for lyft credit i can t use cause they ...</td>\n",
       "      <td>thank left credit use caus offer wheelchair va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesti</td>\n",
       "      <td>No hashtags</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>day majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model love take time urd+-!!! dddd d|d|d|</td>\n",
       "      <td>#model</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "      <td>model love take time ord add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: societi #motiv</td>\n",
       "      <td>#motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>fact guid societi motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  father dysfunct selfish drag kid dysfunction. ...   \n",
       "1  thank #lyft credit can't use caus offer wheelc...   \n",
       "2                                     bihday majesti   \n",
       "3         #model love take time urd+-!!! dddd d|d|d|   \n",
       "4                         factsguide: societi #motiv   \n",
       "\n",
       "                       Hash words  \\\n",
       "0                            #run   \n",
       "1  #lyft #disapointed #getthanked   \n",
       "2                     No hashtags   \n",
       "3                          #model   \n",
       "4                     #motivation   \n",
       "\n",
       "                                        clean_tweet2  \\\n",
       "0  when a father is dysfunctional and is so selfi...   \n",
       "1  thanks for lyft credit i can t use cause they ...   \n",
       "2                                bihday your majesty   \n",
       "3  model i love you take with you all the time in...   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                     corrected_tweet  \n",
       "0      father dysfunct selfish drag kid dysfunct run  \n",
       "1  thank left credit use caus offer wheelchair va...  \n",
       "2                                        day majesti  \n",
       "3                       model love take time ord add  \n",
       "4                            fact guid societi motiv  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save dataframed and corpus1 and courpus2\n",
    "data_frame.to_pickle('data/dataframe.pkl')\n",
    "data_frame.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
